{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5975,"status":"ok","timestamp":1668444681644,"user":{"displayName":"AKASH SINGH IIIT Dharwad","userId":"09449469462329399013"},"user_tz":-330},"id":"11y_109IaNyM"},"outputs":[],"source":["import glob\n","import numpy as np\n","import pandas as pd\n","import csv\n","import h5py\n","import tensorflow as tf\n","import keras\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import Layer, Dense, Dropout, LSTM, GRU, Conv1D, Conv2D, Conv2DTranspose, MaxPooling2D, AveragePooling2D, UpSampling2D\n","from tensorflow.keras.layers import concatenate, GlobalMaxPooling1D, Flatten, BatchNormalization\n","from tensorflow.keras.layers import Activation, Reshape, TimeDistributed, Embedding, Input\n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adamax, Adadelta, Adagrad, Nadam\n","from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.regularizers import l1, l2\n","# from keras import backend as K\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from tqdm import tqdm\n","\n","import parse_files as p\n","from features import bigram_features0, bigram_features1, bigram_features2, bigram_features3, bigram_features4, bigram_features5\n","\n","from numpy.random import seed\n","from tensorflow.python.keras.backend import set_session\n","from keras import regularizers"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"XcsZAKFl-uy0"},"outputs":[],"source":["# class TransformerBlock(layers.Layer):\n","#   def __init__(self, embed_dim, num_heads, foldlabels, learning_rate=0.001):\n","#     super(TransformerBlock, self).__init__()\n","\n","#     self.attention = layers.MultiHeadAttention(num_heads, embed_dim)\n","#     self.dropout1 = layers.Dropout(learning_rate)\n","#     self.norm1 = layers.LayerNormalization(epsilon=1e-6)\n","\n","#     self.feed_forward_network = keras.Sequential([\n","#         Dense(512, activation='tanh'),\n","# \t\t    Dense(128, activation='tanh')\n","#     ])\n","\n","#     self.droput2 = layers.Dropout(learning_rate)\n","#     self.norm2 = layers.LayerNormalization(epsilon=1e-6)\n","#     self.softmax = Dense(foldlabels.shape[1], activation='softmax', name='main_output', kernel_regularizer=l2(0.01))\n","\n","#   def call(self, inputs):\n","#     batch_size, seq_len = tf.shape(inputs)[0], tf.shape(inputs)[1]"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# clsfeature = True\n","clsfeature = False\n","\n","\n","rawdata = 'hmm'\n","# rawdata = 'pssm'\n","\n","# predtype = 'Class'\n","predtype = 'Fold'\n","\n","# dataset = 'dd'\n","# dataset = 'edd'\n","# dataset = 'tg'\n","dataset = 'SCOPe'\n","#dataset = '25_SCOPe_DDEDDTG'"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["np.random.seed(0)\n","tf.random.set_seed(0)\n","\n","labels = []\n","hmm = []\n","pssm = []\n","seq = []\n","seqlen = 200\n","biGram_features0 = []\n","biGram_features1 = []\n","biGram_features2 = []\n","biGram_features3 = []\n","biGram_features4 = []\n","biGram_features5 = []\n","\n","\n","# Load all the filenames of PSSM's\n","filelist = glob.glob('./data/'+dataset+'/'+rawdata+'/*.txt')\n","\n","# Read all the labels of the given dataset\n","if dataset == \"SCOPe\":\n","\tlabel_for_seq = pd.read_csv(\"./astral_2_08_final.csv\") # Make sure all the sequences are in uppercase\n","else:\n","\tlabel_for_seq = p.load_labels('./data/'+dataset+'_'+predtype+'_labels.txt')\n","\n","# Read all the HMM and PSSM matrices of the given dataset\n","for i in range(0, len(filelist)):\n","\t# HMM data\n","\tif(rawdata == 'hmm'):\n","\t\tseq_hmm,prob_hmm,extras_hmm = p.parse_hmm(filelist[i])\n","\t\ttempseq = seq_hmm.upper()\n","\t\tseq.append(tempseq)\n","\t\tif dataset == \"SCOPe\":\n","\t\t\tlabels.append(label_for_seq.loc[label_for_seq[\"sequence\"] == tempseq][\"fold\"].values[0])\n","\t\telse:\n","\t\t\tlabels.append(label_for_seq[seq_hmm.upper()])\n","\t\tif(clsfeature):\n","\t\t\tbiGram_features0.append(((np.append((bigram_features0(prob_hmm)), (p.get_class_label(dataset, label_for_seq[tempseq])))).reshape(1, -1)))\n","\t\t\tbiGram_features1.append(((np.append((bigram_features1(prob_hmm)), (p.get_class_label(dataset, label_for_seq[tempseq])))).reshape(1, -1)))\n","\t\t\tbiGram_features2.append(((np.append((bigram_features2(prob_hmm)), (p.get_class_label(dataset, label_for_seq[tempseq])))).reshape(1, -1)))\n","\t\t\tbiGram_features3.append(((np.append((bigram_features3(prob_hmm)), (p.get_class_label(dataset, label_for_seq[tempseq])))).reshape(1, -1)))\n","\t\t\tbiGram_features4.append(((np.append((bigram_features4(prob_hmm)), (p.get_class_label(dataset, label_for_seq[tempseq])))).reshape(1, -1)))\n","\t\t\tbiGram_features5.append(((np.append((bigram_features5(prob_hmm)), (p.get_class_label(dataset, label_for_seq[tempseq])))).reshape(1, -1)))\n","\t\telse:\n","\t\t\tbiGram_features0.append(bigram_features0(prob_hmm))\n","\t\t\tbiGram_features2.append(bigram_features2(prob_hmm))\n","\t\t\tbiGram_features3.append(bigram_features3(prob_hmm))\n","\t\t\tbiGram_features4.append(bigram_features4(prob_hmm))\n","\t\t\tbiGram_features1.append(bigram_features1(prob_hmm))\n","\t\t\tbiGram_features5.append(bigram_features5(prob_hmm))\n","\n","\t\tnorm_hmm = prob_hmm + 0.01\n","\t\tif(len(norm_hmm) < seqlen):\n","\t\t\tfor j in range(seqlen-len(norm_hmm)):\n","\t\t\t\tnorm_hmm = np.concatenate((norm_hmm,norm_hmm[0]*0))\n","\t\telse:\n","\t\t\tnorm_hmm = norm_hmm[:seqlen]\n","\t\thmm.append(norm_hmm)\n","\n","\t# PSSM data\n","\telse:  \n","\t\tseq_pssm,prob_pssm,lprob_pssm,extra_pssm = p.parse_pssm(filelist[i])\n","\t\ttempseq = seq_pssm.upper()\n","\t\tseq.append(tempseq)\n","\t\tlabels.append(label_for_seq[seq_pssm.upper()])\t    \n","\t\tif(clsfeature):\n","\t\t\tbiGram_features0.append(((np.append((bigram_features0(prob_pssm)), (p.get_class_label(dataset, label_for_seq[tempseq])))).reshape(1, -1)))\n","\t\t\tbiGram_features1.append(((np.append((bigram_features1(prob_pssm)), (p.get_class_label(dataset, label_for_seq[tempseq])))).reshape(1, -1)))\n","\t\t\tbiGram_features2.append(((np.append((bigram_features2(prob_pssm)), (p.get_class_label(dataset, label_for_seq[tempseq])))).reshape(1, -1)))\n","\t\t\tbiGram_features3.append(((np.append((bigram_features3(prob_pssm)), (p.get_class_label(dataset, label_for_seq[tempseq])))).reshape(1, -1)))\n","\t\t\tbiGram_features4.append(((np.append((bigram_features4(prob_pssm)), (p.get_class_label(dataset, label_for_seq[tempseq])))).reshape(1, -1)))\n","\t\t\tbiGram_features5.append(((np.append((bigram_features5(prob_pssm)), (p.get_class_label(dataset, label_for_seq[tempseq])))).reshape(1, -1)))\n","\t\telse:\n","\t\t\tbiGram_features0.append(bigram_features0(prob_pssm))\n","\t\t\tbiGram_features2.append(bigram_features2(prob_pssm))\n","\t\t\tbiGram_features3.append(bigram_features3(prob_pssm))\n","\t\t\tbiGram_features4.append(bigram_features4(prob_pssm))\n","\t\t\tbiGram_features1.append(bigram_features1(prob_pssm))\n","\t\t\tbiGram_features5.append(bigram_features5(prob_pssm))\n","\n","\t\tnorm_pssm = prob_pssm + 0.01\n","\n","\t\tif(len(norm_pssm) < seqlen):\n","\t\t\tfor j in range(seqlen-len(norm_pssm)):\n","\t\t\t\tnorm_pssm = np.concatenate((norm_pssm,norm_pssm[0]*0))\n","\t\telse:\n","\t\t\tnorm_pssm = norm_pssm[:seqlen]\n","\t\tpssm.append(norm_pssm)\n","\n","labels = np.array(labels)\n","# print(\"Labels=\",labels)\n","num_classes =  len(np.unique(labels))\n","foldlabels = pd.get_dummies(labels).values\n","# print(\"foldlabels=\",foldlabels)\n","sequences = np.array(seq)\n","# print(sequences.shape)\n","biGram0 = np.array(biGram_features0)\n","biGram1 = np.array(biGram_features1)\n","biGram2 = np.array(biGram_features2)\n","biGram3 = np.array(biGram_features3)\n","biGram4 = np.array(biGram_features4)\n","biGram5 = np.array(biGram_features5)\n","# np.random.shuffle(hmm)\n","# np.random.shuffle(pssm)\n","hmm = np.array(hmm)\n","pssm = np.array(pssm)\n","\n","if(rawdata == 'hmm'):\n","\tmatrixdata = hmm\n","else:\n","\tmatrixdata = pssm\n","\n","no_filters1 = 4"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"vLUYxzRZbVKA"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From C:\\Users\\Administrator\\AppData\\Local\\Temp\\2\\ipykernel_4572\\2728612245.py:6: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n","\n","Fold- 1 :  [1.6671605110168457, 0.8543999791145325]\n","20/20 [==============================] - 0s 5ms/step\n","pred_scores shape = (625, 171)\n","Fold- 2 :  [1.7678273916244507, 0.8416000008583069]\n","20/20 [==============================] - 0s 5ms/step\n","pred_scores shape = (625, 171)\n","Fold- 3 :  [1.8220089673995972, 0.8223999738693237]\n","20/20 [==============================] - 0s 4ms/step\n","pred_scores shape = (625, 171)\n","Fold- 4 :  [1.8152962923049927, 0.8303999900817871]\n","20/20 [==============================] - 0s 5ms/step\n","pred_scores shape = (625, 171)\n","Fold- 5 :  [1.8196617364883423, 0.8191999793052673]\n","20/20 [==============================] - 0s 5ms/step\n","pred_scores shape = (625, 171)\n","Fold- 6 :  [1.718684196472168, 0.8399999737739563]\n","20/20 [==============================] - 0s 5ms/step\n","pred_scores shape = (625, 171)\n","Fold- 7 :  [1.6944830417633057, 0.86080002784729]\n","20/20 [==============================] - 0s 5ms/step\n","pred_scores shape = (625, 171)\n","Fold- 8 :  [1.675512671470642, 0.8543999791145325]\n","20/20 [==============================] - 0s 5ms/step\n","pred_scores shape = (625, 171)\n","Fold- 9 :  [1.7694470882415771, 0.8256000280380249]\n","20/20 [==============================] - 0s 4ms/step\n","pred_scores shape = (625, 171)\n","Fold- 10 :  [1.78073251247406, 0.8253205418586731]\n","20/20 [==============================] - 0s 5ms/step\n","pred_scores shape = (624, 171)\n","Class Features = False -- 10-cross fold accuracy of Protein Fold Prediction of SCOPe using hmm is :0.8374120473861695\n","\n","10 Fold Accuracies: [0.8543999791145325, 0.8416000008583069, 0.8223999738693237, 0.8303999900817871, 0.8191999793052673, 0.8399999737739563, 0.86080002784729, 0.8543999791145325, 0.8256000280380249, 0.8253205418586731]\n","# of Labels: 171\n","# of Labels: 171\n","hybrid_features count: (None, 2512)\n"]}],"source":["with tf.device('/device:GPU:0'):\n","\tf=0\n","\tconfig=tf.compat.v1.ConfigProto()\n","\tconfig.gpu_options.allow_growth = True\n","\tconfig.gpu_options.per_process_gpu_memory_fraction = 0.2\n","\ttf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\t\t\n","\n","\tacc_k_fold = []\n","\t# kf = KFold(n_splits=10, shuffle=True, random_state=8)\n","\tkf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","\n","\tfor train, test in kf.split(sequences, labels):\n","\t\tf=f+1\n","\t\tX_train, X_test = matrixdata[train], matrixdata[test]\n","\t\tY_train, Y_test = foldlabels[train], foldlabels[test]\n","\t\tX_biGram0_Train, X_biGram0_Test = biGram0[train], biGram0[test]\n","\t\tX_biGram1_Train, X_biGram1_Test = biGram1[train], biGram1[test]\n","\t\tX_biGram2_Train, X_biGram2_Test = biGram2[train], biGram2[test]\n","\t\tX_biGram3_Train, X_biGram3_Test = biGram3[train], biGram3[test]\n","\t\tX_biGram4_Train, X_biGram4_Test = biGram4[train], biGram4[test]\n","\t\tX_biGram5_Train, X_biGram5_Test = biGram5[train], biGram5[test]\n","\n","\t\t# print(\"X_train:\", X_train.shape)\n","\t\t# print(\"Y_train:\", Y_train.shape)\n","\t\t# print(\"X_biGram0_Train:\", X_biGram0_Train.shape)\n","\t\t# print(\"X_biGram1_Train:\", X_biGram1_Train.shape)\n","\t\t# print(\"X_biGram2_Train:\", X_biGram2_Train.shape)\n","\t\t# print(\"X_biGram3_Train:\", X_biGram3_Train.shape)\n","\t\t# print(\"X_biGram4_Train:\", X_biGram4_Train.shape)\n","\t\t# print(\"X_biGram5_Train:\", X_biGram5_Train.shape)\n","\n","\t\tcnn_input = Input(shape=(seqlen,20), name='cnn_input')\t\t\n","\t\tc_input = Reshape((seqlen,20,1))(cnn_input)\t\t\n","\t\tc_output1 = Conv2D(no_filters1, (5,5),  activation='tanh', strides=5, padding='same')(c_input)\n","\t\tm_output1 = MaxPooling2D((3,3), strides=3, padding='same')(c_output1)\n","\t\tf_input = Flatten()(m_output1)\n","\t\t# print(\"Convolution Features Size: \", f_input.shape)\n","\t\tbigram_input0 = Input(shape=(X_biGram0_Train.shape[1], X_biGram0_Train.shape[2]), name='bigram_input0')\n","\t\tbg0_input = Flatten()(bigram_input0)\n","\n","\t\tbigram_input1 = Input(shape=(X_biGram1_Train.shape[1], X_biGram1_Train.shape[2]), name='bigram_input1')\n","\t\tbg1_input = Flatten()(bigram_input1)\n","\n","\t\tbigram_input2 = Input(shape=(X_biGram2_Train.shape[1], X_biGram2_Train.shape[2]), name='bigram_input2')\n","\t\tbg2_input = Flatten()(bigram_input2)\n","\n","\t\tbigram_input3 = Input(shape=(X_biGram3_Train.shape[1], X_biGram3_Train.shape[2]), name='bigram_input3')\n","\t\tbg3_input = Flatten()(bigram_input3)\n","\n","\t\tbigram_input4 = Input(shape=(X_biGram4_Train.shape[1], X_biGram4_Train.shape[2]), name='bigram_input4')\n","\t\tbg4_input = Flatten()(bigram_input4)\n","\n","\t\tbigram_input5 = Input(shape=(X_biGram5_Train.shape[1], X_biGram5_Train.shape[2]), name='bigram_input5')\n","\t\tbg5_input = Flatten()(bigram_input5)\n","\n","\t\tbigram_input5 = Input(shape=(X_biGram5_Train.shape[1], X_biGram5_Train.shape[2]), name='bigram_input5')\n","\t\tbg5_input = Flatten()(bigram_input5)\n","\n","\t\thybrid_features = concatenate([f_input, bg0_input, bg1_input, bg2_input, bg3_input, bg4_input, bg5_input], axis=-1)\n","\t\t# hybrid_features = f_input\n","\t\t# hybrid_features = concatenate([bg0_input, bg1_input, bg2_input, bg3_input, bg4_input, bg5_input, sgt_input_flatten], axis=-1)\n","\n","\t\t# print(\"Hybrid Features Size: \", hybrid_features.shape)\n","\t\td_output2 = Dense(512, activation='tanh')(hybrid_features)\n","\t\td_output2 = Dense(128, activation='tanh')(d_output2)\n","\t\tmain_output = Dense(foldlabels.shape[1], activation='softmax', name='main_output', kernel_regularizer=l2(0.01))(d_output2)\n","\n","\t\tmodel = Model(inputs=[cnn_input, bigram_input0, bigram_input1, bigram_input2, bigram_input3, bigram_input4, bigram_input5], outputs=[main_output])\n","\t\tmodel.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\t\t# model.summary()\n","\n","\t\tearlyStopping = EarlyStopping(monitor='val_accuracy', patience=50, verbose=0, mode='auto')\n","\t\tload_file = \"./model/\"+dataset+\"_SXG_BiGram_best.h5\"\n","\t\tcheckpointer = ModelCheckpoint(monitor='val_accuracy', filepath=load_file, verbose=0, save_best_only=True)\n","\n","\t\thistory=model.fit({'cnn_input': X_train, 'bigram_input0': X_biGram0_Train, 'bigram_input1': X_biGram1_Train, 'bigram_input2': X_biGram2_Train, 'bigram_input3': X_biGram3_Train, 'bigram_input4': X_biGram4_Train, 'bigram_input5': X_biGram5_Train}, {'main_output': Y_train}, \n","\t\t\tvalidation_data=({'cnn_input': X_test, 'bigram_input0': X_biGram0_Test, 'bigram_input1': X_biGram1_Test, 'bigram_input2': X_biGram2_Test, 'bigram_input3': X_biGram3_Test, 'bigram_input4': X_biGram4_Test, 'bigram_input5': X_biGram5_Test},{'main_output': Y_test}), \n","\t\t\tepochs=500, batch_size=64, callbacks=[checkpointer, earlyStopping], verbose=0)\n","\n","\t\tmodel.load_weights(load_file)\n","\t\tscore = model.evaluate({'cnn_input': X_test, 'bigram_input0': X_biGram0_Test, 'bigram_input1': X_biGram1_Test, 'bigram_input2': X_biGram2_Test, 'bigram_input3': X_biGram3_Test, 'bigram_input4': X_biGram4_Test, 'bigram_input5': X_biGram5_Test},{'main_output': Y_test}, verbose=0, batch_size=1)\n","\t\tprint(\"Fold-\",f, \": \", score)\n","\n","\t\tacc_k_fold.append(score[1])\n","\n","\t\tpred_scores = model.predict({'cnn_input': X_test, 'bigram_input0': X_biGram0_Test, 'bigram_input1': X_biGram1_Test, 'bigram_input2': X_biGram2_Test, 'bigram_input3': X_biGram3_Test, 'bigram_input4': X_biGram4_Test, 'bigram_input5': X_biGram5_Test})\n","\t\tprint(\"pred_scores shape =\", pred_scores.shape)\n","\n","\t\t# foldslabel=['Globin-like', 'Cytochrome C', 'DNA-binding 3-helical bundle', 'Immunoglobulin-like Beta-sandwich', 'Common fold of diphtheria toxin/trascription factors/transcription', 'Cupredoxins', 'TIM beta/alpha-barrel', 'NAD(P)-binding Rossmann-fold domains ', 'FAD/NAD(P)-binding domain', '4-Helical up-and-down bundle', '4-Helical cytokines', 'Aplha-EF-hand', 'SAM domain-like', 'Galactose-binding domain-like', 'Viral coat and capsid proteins', 'Concanavalin A-like lectins/glucanases', 'SH3-like barrel', 'OB-fold', 'Trefoil', 'Trypsin-like serine protease', 'Lipocalins', 'Double-stranded Beta-helix', 'Flavodoxin-like', 'Adenine nucleotide alpha hydrolase-like ', 'P-loop containing nucleoside triphosphate hydrolases ', 'Thioredoxin fold', 'Ribonuclease H-like motif', 'Phosphorylase/hydrolase-like', 'S-adenosyl-L-methionine-dependent methyltransferases', 'Alpha/beta-Hydrolases', 'Periplasmic binding protein-like I', 'Beta-Grasp (ubiquitin-like) ', 'Cystatin-like', 'Ferredoxin-like', 'Alpha-alpha super helix', 'Nucleoplasmin-like']\n","\n","\t\t# for i in range(pred_scores.shape[0]):\n","\t\t# \tif np.sum(pred_scores[i,:]) != 0:\n","\t\t# \t\tres=np.argmax(pred_scores[i,:])\n","\t\t# \t\tprint(\"Fold is:\", foldslabel[res])\n","\n","\t\t# \telse:\n","\t\t# \t\tprint(\"Danger\")\n","\n","\t\t# y_classes = y_prob.argmax(axis=-1)\n","\t\t# print(\"Model Evaluate output\", y_classes)\n","\n","\n","\tresdata = \"Class Features = \"+str(clsfeature)+\" -- 10-cross fold accuracy of Protein \"+predtype+\" Prediction of \"+dataset+\" using \"+rawdata+\" is :\"+str(np.mean(acc_k_fold))+\"\\n\"\n","\n","\tprint(resdata)\n","\tprint(\"10 Fold Accuracies:\", acc_k_fold)\n","\n","print(\"# of Labels:\", num_classes)\n","print(\"# of Labels:\", foldlabels.shape[1])\n","print(\"hybrid_features count:\", hybrid_features.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1mGBcn0gnXY0h4gLPuBRNIn-pnujeC7uc","timestamp":1668444601340}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.5 ('protein-env': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"vscode":{"interpreter":{"hash":"2f81477a04ac803d382ae7d6eef639787df1946e019eec2800176f10d07e3db8"}}},"nbformat":4,"nbformat_minor":0}
